{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4004af63",
   "metadata": {},
   "source": [
    "# 07 - Prediction Serving\n",
    "\n",
    "The purpose of the notebook is to show how to use the deployed model for online and batch prediction.\n",
    "The notebook covers the following tasks:\n",
    "1. Test the endpoints for online prediction.\n",
    "2. Use the uploaded custom model for batch prediction.\n",
    "3. Run a the batch prediction pipeline using `Vertex Pipelines`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dad1f75",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d02a9d5",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f3ce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e73bc25",
   "metadata": {},
   "source": [
    "### Setup Google Cloud project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ea9b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = '' # Change to your project id.\n",
    "REGION = '' # Change to your region.\n",
    "BUCKET = ''\n",
    "\n",
    "if PROJECT == \"\" or PROJECT is None or PROJECT == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = !gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT = shell_output[0]\n",
    "    \n",
    "if BUCKET == \"\" or BUCKET is None or BUCKET == \"[your-bucket-name]\":\n",
    "    # Get your bucket name to GCP project id\n",
    "    BUCKET = PROJECT\n",
    "    # Try to create the bucket if it doesn't exists\n",
    "    ! gsutil mb -l $REGION gs://$BUCKET\n",
    "    print(\"\")\n",
    "    \n",
    "print(\"Project ID:\", PROJECT)\n",
    "print(\"Region:\", REGION)\n",
    "print(\"Bucket name:\", BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecba79b0",
   "metadata": {},
   "source": [
    "### Set configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537732be",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION = 'v01'\n",
    "DATASET_DISPLAY_NAME = 'tfdf-rules'\n",
    "MODEL_DISPLAY_NAME = f'{DATASET_DISPLAY_NAME}-classifier-{VERSION}'\n",
    "ENDPOINT_DISPLAY_NAME = f'{DATASET_DISPLAY_NAME}-classifier'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e508dd0",
   "metadata": {},
   "source": [
    "## 1. Making Online Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38be76f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.init(\n",
    "    project=PROJECT,\n",
    "    location=REGION,\n",
    "    staging_bucket=BUCKET\n",
    ")\n",
    "\n",
    "endpoint_name = vertex_ai.Endpoint.list(\n",
    "    filter=f'display_name={ENDPOINT_DISPLAY_NAME}', \n",
    "    order_by=\"update_time\")[-1].gca_resource.name\n",
    "\n",
    "endpoint = vertex_ai.Endpoint(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b8053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instances = [  \n",
    "    {\n",
    "        \"feature_1\": [0],\n",
    "        \"feature_2\": [1],\n",
    "        \"feature_3\": [0],\n",
    "        \"feature_4\": [0],\n",
    "        \"feature_5\": [1],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cb447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = endpoint.predict(test_instances).predictions\n",
    "\n",
    "for prediction in predictions:\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76528a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "CSV_DATA_PATH = 'data/data.csv'\n",
    "df = pd.read_csv(CSV_DATA_PATH)\n",
    "\n",
    "index_of_label = np.argmax(predictions) - 1\n",
    "print(f'index_of_label: {index_of_label}')\n",
    "\n",
    "print(df)\n",
    "df.iloc[index_of_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330d9dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanations aren't supported on this model.\n",
    "# explanations = endpoint.explain(test_instances).explanations\n",
    "\n",
    "# for explanation in explanations:\n",
    "#     print(explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f128b46e",
   "metadata": {},
   "source": [
    "### (Optional) Build the ML container image\n",
    "\n",
    "This is the `TFX` runtime environment for the training pipeline steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24fa5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $TFX_IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3949cc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud builds submit --tag $TFX_IMAGE_URI . --timeout=15m --machine-type=e2-highcpu-8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a9890d",
   "metadata": {},
   "source": [
    "### Compile pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c8a3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tfx_pipelines import runner\n",
    "\n",
    "pipeline_definition_file = f'{config.PIPELINE_NAME}.json'\n",
    "pipeline_definition = runner.compile_prediction_pipeline(pipeline_definition_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc2792a",
   "metadata": {},
   "source": [
    "### Submit run to Vertex Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dcc92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2.google.client import AIPlatformClient\n",
    "\n",
    "pipeline_client = AIPlatformClient(\n",
    "    project_id=PROJECT, region=REGION)\n",
    "                 \n",
    "pipeline_client.create_run_from_job_spec(\n",
    "    job_spec_path=pipeline_definition_file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0d5bef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m79",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m79"
  },
  "interpreter": {
   "hash": "969d35e749fda7fadd47ba635ad15fe8638793cf4bed406010c22418a542c5ee"
  },
  "kernelspec": {
   "display_name": "clearsafety-rules",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
